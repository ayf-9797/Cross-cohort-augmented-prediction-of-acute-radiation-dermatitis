##############################
## 0. å®‰è£…å¹¶åŠ è½½æ‰€éœ€åŒ…
##############################
needed_pkgs <- c("caret", "MLmetrics", "e1071", "ggplot2", "purrr", 
                 "dplyr", "tidyr", "readxl", "magrittr", "ROCR","xlsx")
new_pkgs <- needed_pkgs[!(needed_pkgs %in% installed.packages()[,"Package"])]
if(length(new_pkgs)) install.packages(new_pkgs)

# æ£€æŸ¥å¹¶å®‰è£…å¯é€‰åŒ…
if (!require("rmda")) {
  install.packages("rmda")
}

# åŠ è½½æ‰€æœ‰åŒ…
lapply(needed_pkgs, library, character.only = TRUE)
library(rmda)

set.seed(100)  # å¯å¤ç°çš„éšæœºç§å­
NEWDATA=F
BALANCE_SAMPLE=F
SUB_THRESHOLD=F
SUB_ROC=F
##############################
## 1. æ•°æ®é¢„å¤„ç†
##############################
# ç»¼åˆæ¨¡å‹
# patient_df <- read_excel("../data/202601/ccp_lasso.xlsx")
# å°æ¨¡å‹
patient_df <- read_excel('../data/202601/single_cohort_lasso.xlsx')

predictors <- setdiff(names(patient_df), "psoriasis")  # ç›®æ ‡å˜é‡æ˜¯ "psoriasis"
p <- length(predictors)

identify_categories <- function(x) {
  category_threshold <- 9
  if (is.numeric(x)) {
    return(length(unique(x)) <= category_threshold)
  }
  return(TRUE)
}
category_vars <- names(patient_df)[sapply(patient_df, identify_categories)]
category_vars <- setdiff(category_vars, "psoriasis")  # ç¡®ä¿psoriasisä¸è¢«å½“ä½œåˆ†ç±»å˜é‡
category_vars <- setdiff(category_vars, "Control") 
patient_df[category_vars] <- lapply(patient_df[category_vars], as.factor)
patient_df$psoriasis <- factor(patient_df$psoriasis, 
                               levels = c("0", "1"), 
                               labels = c("No", "Yes"))
##############################
## 2. è‡ªå®šä¹‰ F1-score è¯„ä¼°å‡½æ•°
##############################
f1_summary <- function(data, lev = NULL, model = NULL) {
  f1 <- F1_Score(y_true = data$obs,
                 y_pred = data$pred,
                 positive = "Yes")
  c(F1 = f1)
}

##############################
## 3. äº”æŠ˜äº¤å‰éªŒè¯å‚æ•°è®¾å®š
##############################
get_balanced_index <- function(x,name,value){
  # name = as.formula(name)
  idx_a0 <- which(x[name] == value)
  idx_a1 <- which(x[name] != value)
  folds_a0 <- createFolds(x$psoriasis[idx_a0], k = 5, returnTrain = FALSE)
  folds_a1 <- createFolds(x$psoriasis[idx_a1], k = 5, returnTrain = FALSE)
  index_list <- list()
  for (i in 1:5) {
    index_list[[i]] <- c(idx_a0[folds_a0[[i]]], idx_a1[folds_a1[[i]]])
  }
  return(index_list)
}
if (BALANCE_SAMPLE){
  test_ids <- get_balanced_index(patient_df,"Control",0)
  all_idx <- seq_len(nrow(patient_df))
  train_ids <- lapply(test_ids, function(val_idx) setdiff(all_idx, val_idx))
  patient_df <- select(patient_df, -"Control")
  ctrl <- trainControl(method = "cv",
                       number = 5,
                       summaryFunction = f1_summary,
                       index = train_ids,
                       indexOut = test_ids,
                       classProbs = TRUE,
                       savePredictions = "final",
                       verboseIter = FALSE)
} else {
  patient_df <- select(patient_df, -"Control")
  ctrl <- trainControl(method = "cv",
                       number = 5,
                       summaryFunction = f1_summary,
                       classProbs = TRUE,
                       savePredictions = "final",
                       verboseIter = FALSE)
}

##############################
## 4. è®­ç»ƒå¤šå…ƒé€»è¾‘å›å½’æ¨¡å‹ (Logistic Regression)
##############################
# å¯¹äºé€»è¾‘å›å½’ï¼Œä¸éœ€è¦è°ƒå‚ç½‘æ ¼
logit_model <- train(psoriasis ~ .,
                     data = patient_df,
                     method = "glm",
                     family = "binomial",
                     trControl = ctrl,
                     preProcess = c("center", "scale"),  # æ ‡å‡†åŒ–å¤„ç†
                     metric = "F1")

##############################
## 5. æå–è¯„ä¼°ç»“æœå¹¶è¾“å‡º
##############################

# æå–äº¤å‰éªŒè¯ç»“æœ
cv_results <- logit_model$resample
mean_F1 <- mean(cv_results$F1)
best_F1 <- max(cv_results$F1)

cat("æ¨¡å‹è®­ç»ƒå®Œæˆ\n")
cat("æ¨¡å‹ç±»å‹: å¤šå…ƒé€»è¾‘å›å½’ (Multivariate Logistic Regression)\n")
cat("äº”æŠ˜å¹³å‡ F1-score:", round(mean_F1, 3), "\n")
cat("æœ€ä½³æŠ˜ F1-score:", round(best_F1, 3), "\n")

# æå–é¢„æµ‹ç»“æœ
pred_best <- logit_model$pred

##############################
## 6. ROCå’ŒPRCæ›²çº¿ç»˜åˆ¶
##############################

# 6.1. å‡†å¤‡æ•°æ®
pred_folds <- pred_best %>%
  group_split(Resample)

# 6.2. æ‰‹åŠ¨è®¡ç®—æ¯ä¸ªfoldçš„ROCå’ŒPRCæ›²çº¿

# å­˜å‚¨æ‰€æœ‰foldçš„æ›²çº¿æ•°æ®
all_roc_data <- list()
all_prc_data <- list()
auc_values <- numeric(5)
prauc_values <- numeric(5)

for(i in 1:length(pred_folds)) {
  fold_data <- pred_folds[[i]]
  
  # åˆ›å»º prediction å¯¹è±¡
  pred_obj <- prediction(fold_data$Yes, fold_data$obs == "Yes")
  
  # ROC æ›²çº¿
  roc_perf <- performance(pred_obj, "tpr", "fpr")
  auc_perf <- performance(pred_obj, "auc")
  auc_values[i] <- auc_perf@y.values[[1]]
  
  all_roc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    fpr = roc_perf@x.values[[1]],
    tpr = roc_perf@y.values[[1]],
    auc = auc_values[i]
  )
  
  # PRC æ›²çº¿
  prc_perf <- performance(pred_obj, "prec", "rec")
  
  # è®¡ç®— PRAUC
  prauc_perf <- performance(pred_obj, "aucpr")
  prauc_values[i] <- prauc_perf@y.values[[1]]
  
  # å¤„ç†precisionä¸­çš„NAå€¼ï¼ˆå½“recall=0æ—¶ï¼‰
  precision_vals <- prc_perf@y.values[[1]]
  recall_vals <- prc_perf@x.values[[1]]
  
  # ç§»é™¤NAå€¼
  valid_idx <- !is.na(precision_vals)
  
  all_prc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    recall = recall_vals[valid_idx],
    precision = precision_vals[valid_idx],
    prauc = prauc_values[i]
  )
}

# åˆå¹¶æ‰€æœ‰foldçš„æ•°æ®
roc_plot_data <- bind_rows(all_roc_data) %>%
  mutate(fold_label = paste0(fold, " (AUROC = ", round(auc, 3), ")"))

prc_plot_data <- bind_rows(all_prc_data) %>%
  mutate(fold_label = paste0(fold, " (AUPRC = ", round(prauc, 3), ")"))

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
mean_auroc <- mean(auc_values)
ci_auroc <- quantile(auc_values, c(0.025, 0.975))
mean_auprc <- mean(prauc_values)
ci_auprc <- quantile(prauc_values, c(0.025, 0.975))

# 6.3. ç»˜åˆ¶ ROC æ›²çº¿
p_roc <- ggplot(roc_plot_data, aes(x = fpr, y = tpr, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_abline(linetype = "dashed", color = "grey50") +
  coord_equal() +
  labs(
    title = "Logistic Regression - 5-Fold Cross-Validation ROC Curves",
    subtitle = sprintf("Mean AUROC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auroc, ci_auroc[1], ci_auroc[2]),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    color = "Fold (AUROC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  )

print(p_roc)
ggsave("ROC_5-Fold_Logit.png", p_roc, width = 10, height = 7, dpi = 300)

# 6.4. ç»˜åˆ¶ PRC æ›²çº¿

# è®¡ç®—åŸºçº¿
total_positives <- sum(sapply(pred_folds, function(x) sum(x$obs == "Yes")))
total_samples <- sum(sapply(pred_folds, nrow))
baseline_precision <- total_positives / total_samples

p_prc <- ggplot(prc_plot_data, aes(x = recall, y = precision, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_hline(yintercept = baseline_precision, linetype = "dashed", color = "grey50") +
  annotate("text", x = 0.5, y = baseline_precision - 0.03, 
           label = paste("Random Classifier Baseline =", round(baseline_precision, 3)),
           color = "grey50", size = 3.5) +
  labs(
    title = "Logistic Regression - 5-Fold Cross-Validation PR Curves",
    subtitle = sprintf("Mean AUPRC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auprc, ci_auprc[1], ci_auprc[2]),
    x = "Recall (Sensitivity)",
    y = "Precision",
    color = "Fold (AUPRC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  ) +
  xlim(0, 1) + ylim(0, 1)

print(p_prc)
ggsave("PRC_5-Fold_Logit.png", p_prc, width = 10, height = 7, dpi = 300)

# 6.5. æ·»åŠ å¹³å‡æ›²çº¿çš„ROCå›¾

# è®¡ç®—å¹³å‡ ROC æ›²çº¿
fpr_seq <- seq(0, 1, length.out = 100)
tpr_interp <- matrix(NA, nrow = length(fpr_seq), ncol = 5)

for(i in 1:5) {
  fold_roc <- all_roc_data[[i]]
  f <- approxfun(fold_roc$fpr, fold_roc$tpr, rule = 2)
  tpr_interp[, i] <- f(fpr_seq)
}

avg_roc <- data.frame(
  fpr = fpr_seq,
  tpr = rowMeans(tpr_interp),
  tpr_lower = apply(tpr_interp, 1, quantile, 0.025),
  tpr_upper = apply(tpr_interp, 1, quantile, 0.975)
)

# å¸¦å¹³å‡æ›²çº¿çš„ ROC å›¾
p_roc_with_avg <- p_roc +
  geom_ribbon(data = avg_roc, 
              aes(x = fpr, ymin = tpr_lower, ymax = tpr_upper),
              fill = "black", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = avg_roc, 
            aes(x = fpr, y = tpr),
            color = "black", size = 1.5, inherit.aes = FALSE)

print(p_roc_with_avg)
ggsave("ROC_5-Fold_Logit_with_average.png", p_roc_with_avg, width = 8, height = 7, dpi = 300)

##############################
## 7. åŸºäºYouden Indexçš„éªŒè¯åˆ†æ
##############################

# 7.1 å¯¹æ¯ä¸ªfoldè®¡ç®—æœ€ä½³é˜ˆå€¼å’Œæ€§èƒ½æŒ‡æ ‡
fold_performance <- list()

for(i in 1:length(pred_folds)) {
  fold_data <- pred_folds[[i]]
  
  # è®¡ç®—è¯¥foldçš„Youden Index
  thresholds <- unique(sort(fold_data$Yes, decreasing = TRUE))
  
  youden_results <- map_dfr(thresholds, function(thresh) {
    pred_bin <- ifelse(fold_data$Yes >= thresh, "Yes", "No")
    
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm <- table(Predicted = pred_bin, Actual = fold_data$obs)
    
    # ç¡®ä¿æ··æ·†çŸ©é˜µå®Œæ•´
    if(nrow(cm) == 1 || ncol(cm) == 1) {
      return(NULL)
    }
    
    TP <- cm["Yes", "Yes"]
    FP <- cm["Yes", "No"]
    FN <- cm["No", "Yes"]
    TN <- cm["No", "No"]
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    sensitivity <- TP / (TP + FN)
    specificity <- TN / (TN + FP)
    precision <- TP / (TP + FP)
    accuracy <- (TP + TN) / sum(cm)
    f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)
    youden <- sensitivity + specificity - 1
    
    tibble(
      threshold = thresh,
      sensitivity = sensitivity,
      specificity = specificity,
      precision = precision,
      accuracy = accuracy,
      f1_score = f1_score,
      youden = youden
    )
  }) %>%
    filter(!is.na(youden))
  
  # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
  best_threshold <- youden_results %>%
    filter(youden == max(youden, na.rm = TRUE)) %>%
    dplyr::slice(1)
  
  fold_performance[[i]] <- list(
    fold = i,
    best_threshold = best_threshold$threshold,
    sensitivity = best_threshold$sensitivity,
    specificity = best_threshold$specificity,
    precision = best_threshold$precision,
    accuracy = best_threshold$accuracy,
    f1_score = best_threshold$f1_score,
    youden_index = best_threshold$youden
  )
}

# 7.2 æ±‡æ€»5æŠ˜çš„å¹³å‡æ€§èƒ½
performance_df <- bind_rows(fold_performance)

# è®¡ç®—å¹³å‡æ€§èƒ½å’Œæ ‡å‡†å·®
avg_performance <- performance_df %>%
  summarise(
    mean_threshold = mean(best_threshold),
    sd_threshold = sd(best_threshold),
    mean_sensitivity = mean(sensitivity),
    sd_sensitivity = sd(sensitivity),
    mean_specificity = mean(specificity),
    sd_specificity = sd(specificity),
    mean_precision = mean(precision),
    sd_precision = sd(precision),
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy),
    mean_f1_score = mean(f1_score),
    sd_f1_score = sd(f1_score),
    mean_youden_index = mean(youden_index),
    sd_youden_index = sd(youden_index)
  )

# 7.3 è¾“å‡ºéªŒè¯ç»“æœ
cat("\n", rep("=", 60), "\n", sep = "")
cat("åŸºäºYouden Indexçš„5æŠ˜äº¤å‰éªŒè¯æ€§èƒ½è¯„ä¼°\n")
cat(rep("=", 60), "\n", sep = "")

cat("\nã€å„æŠ˜è¯¦ç»†ç»“æœã€‘\n")
for(i in 1:5) {
  cat(sprintf("\nFold %d:\n", i))
  cat(sprintf("  æœ€ä½³é˜ˆå€¼: %.3f\n", fold_performance[[i]]$best_threshold))
  cat(sprintf("  çµæ•åº¦: %.3f\n", fold_performance[[i]]$sensitivity))
  cat(sprintf("  ç‰¹å¼‚æ€§: %.3f\n", fold_performance[[i]]$specificity))
  cat(sprintf("  ç²¾ç¡®åº¦: %.3f\n", fold_performance[[i]]$precision))
  cat(sprintf("  å‡†ç¡®ç‡: %.3f\n", fold_performance[[i]]$accuracy))
  cat(sprintf("  F1-score: %.3f\n", fold_performance[[i]]$f1_score))
  cat(sprintf("  Youden Index: %.3f\n", fold_performance[[i]]$youden_index))
}

cat("\nã€5æŠ˜å¹³å‡æ€§èƒ½ (å‡å€¼ Â± æ ‡å‡†å·®)ã€‘\n")
cat(sprintf("æœ€ä½³é˜ˆå€¼: %.3f Â± %.3f\n", avg_performance$mean_threshold, avg_performance$sd_threshold))
cat(sprintf("çµæ•åº¦ (Sensitivity): %.3f Â± %.3f\n", avg_performance$mean_sensitivity, avg_performance$sd_sensitivity))
cat(sprintf("ç‰¹å¼‚æ€§ (Specificity): %.3f Â± %.3f\n", avg_performance$mean_specificity, avg_performance$sd_specificity))
cat(sprintf("ç²¾ç¡®åº¦ (Precision): %.3f Â± %.3f\n", avg_performance$mean_precision, avg_performance$sd_precision))
cat(sprintf("å‡†ç¡®ç‡ (Accuracy): %.3f Â± %.3f\n", avg_performance$mean_accuracy, avg_performance$sd_accuracy))
cat(sprintf("F1-score: %.3f Â± %.3f\n", avg_performance$mean_f1_score, avg_performance$sd_f1_score))
cat(sprintf("Youden Index: %.3f Â± %.3f\n", avg_performance$mean_youden_index, avg_performance$sd_youden_index))

# 7.4 å¯è§†åŒ–å„æŠ˜æ€§èƒ½
performance_long <- performance_df %>%
  select(-fold, -best_threshold) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  mutate(metric = case_when(
    metric == "sensitivity" ~ "Sensitivity",
    metric == "specificity" ~ "Specificity",
    metric == "precision" ~ "Precision",
    metric == "accuracy" ~ "Accuracy",
    metric == "f1_score" ~ "F1-score",
    metric == "youden_index" ~ "Youden Index"
  ))

p_fold_performance <- ggplot(performance_long, aes(x = metric, y = value)) +
  geom_boxplot(fill = "#e74c3c", alpha = 0.7) +
  geom_point(size = 3, alpha = 0.8) +
  labs(
    title = "Logistic Regression 5-Fold Cross-Validation Performance Metrics",
    subtitle = "Based on Youden Index Optimal Thresholds",
    x = "Metric",
    y = "Value"
  ) +
  theme_bw(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  ylim(0, 1)

print(p_fold_performance)
ggsave("fold_performance_metrics_ml.png", p_fold_performance, width = 8, height = 6, dpi = 300)
saveRDS(performance_long,file="performance_ml.rds")
##############################
## 8. ä¿å­˜æ¨¡å‹ä¸ç»“æœ
##############################

# ä¿å­˜æ¨¡å‹
saveRDS(logit_model, file = "ml_best_model.rds")

# ä¿å­˜ROCæ•°æ®
ml_roc_data <- list(
  roc_data = all_roc_data,
  prc_data = all_prc_data,
  auc_values = auc_values,
  prauc_values = prauc_values,
  mean_auroc = mean_auroc,
  mean_auprc = mean_auprc,
  ci_auroc = ci_auroc,
  ci_auprc = ci_auprc
)
saveRDS(ml_roc_data, file = "ml_roc_data.rds")

# ä¿å­˜éªŒè¯æ€§èƒ½æ•°æ®
validation_results <- list(
  fold_performance = fold_performance,
  performance_df = performance_df,
  avg_performance = avg_performance
)
saveRDS(validation_results, file = "ml_validation_results.rds")

cat("\nğŸŸ¢ æ¨¡å‹å·²ä¿å­˜ä¸º ml_best_model.rds\n")
cat("ğŸŸ¢ ROC/PRCæ•°æ®å·²ä¿å­˜ä¸º ml_roc_data.rds\n")
cat("ğŸŸ¢ éªŒè¯ç»“æœå·²ä¿å­˜ä¸º ml_validation_results.rds\n")

##############################
## 9. å†³ç­–æ›²çº¿åˆ†æï¼ˆå¯é€‰ï¼‰
##############################

# å‡†å¤‡å†³ç­–æ›²çº¿åˆ†ææ‰€éœ€çš„æ•°æ®
dca_ml_df <- pred_best %>%
  select(prob = Yes, truth = obs) %>%
  mutate(
    model = "ml",
    truth = ifelse(truth == "Yes", 1, 0)  # è½¬æ¢ä¸º0/1æ ¼å¼
  )

saveRDS(dca_ml_df, "dca_ml_df.rds")
cat("ğŸŸ¢ å†³ç­–æ›²çº¿æ•°æ®å·²ä¿å­˜ä¸º dca_ml_df.rds\n")

##############################
## 10. æ¨¡å‹æ€§èƒ½æ€»ç»“æŠ¥å‘Š
##############################
cat("\n", rep("=", 60), "\n", sep = "")
cat("ml æ¨¡å‹äº”æŠ˜äº¤å‰éªŒè¯æ€§èƒ½æ€»ç»“\n")
cat(rep("=", 60), "\n", sep = "")

cat("\n1. æ¨¡å‹å‚æ•°:\n")
cat("   - æ–¹æ³•: Support Vector Machine (Radial Kernel)\n")
cat("   - æœ€ä¼˜å‚æ•°: sigma =", logit_model$bestTune$sigma, ", C =", logit_model$bestTune$C, "\n")

cat("\n2. ROC/PRCæ€§èƒ½:\n")
cat("   - å¹³å‡ AUROC:", round(mean_auroc, 3), 
    sprintf("(95%% CI: %.3f-%.3f)\n", ci_auroc[1], ci_auroc[2]))
cat("   - å¹³å‡ AUPRC:", round(mean_auprc, 3), 
    sprintf("(95%% CI: %.3f-%.3f)\n", ci_auprc[1], ci_auprc[2]))

cat("\n3. åŸºäºYouden Indexçš„éªŒè¯æ€§èƒ½ (å‡å€¼ Â± æ ‡å‡†å·®):\n")
cat("   - æœ€ä½³é˜ˆå€¼:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_threshold, avg_performance$sd_threshold))
cat("   - Sensitivity:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_sensitivity, avg_performance$sd_sensitivity))
cat("   - Specificity:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_specificity, avg_performance$sd_specificity))
cat("   - Precision:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_precision, avg_performance$sd_precision))
cat("   - Accuracy:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_accuracy, avg_performance$sd_accuracy))
cat("   - F1-score:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_f1_score, avg_performance$sd_f1_score))
cat("   - Youden Index:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_youden_index, avg_performance$sd_youden_index))

cat("\n4. è¾“å‡ºæ–‡ä»¶:\n")
cat("   - æ¨¡å‹æ–‡ä»¶: ml_best_model.rds\n")
cat("   - ROC/PRCæ•°æ®: ml_roc_data.rds\n")
cat("   - éªŒè¯ç»“æœ: ml_validation_results.rds\n")
cat("   - å†³ç­–æ›²çº¿æ•°æ®: dca_ml_df.rds\n")
cat("   - å›¾å½¢æ–‡ä»¶:\n")
cat("     * ROC_5-Fold_ml.png\n")
cat("     * PRC_5-Fold_ml.png\n")
cat("     * ROC_5-Fold_ml_with_average.png\n")
cat("     * fold_performance_metrics_ml.png\n")

cat("\n", rep("=", 60), "\n", sep = "")

# å®Œæˆæç¤º
cat("\nâœ… mlæ¨¡å‹åˆ†æå®Œæˆï¼\n")
##### å¦‚æœè¿˜è¦è®¡ç®—åˆ†å±‚æŒ‡æ ‡,å¹¶ä»¥åˆ†å±‚ç‰¹å¾ä½œä¸ºåŸºå‡†è°ƒæ•´é˜ˆå€¼   ###### 
##### å¦‚æœéœ€è¦å…·å¤‡ç‰¹å®šåˆ†å±‚ç‰¹å¾æ‚£è€…çš„ROCå’ŒPRC              ######
if (SUB_ROC){
  # å‡†å¤‡æ•°æ®
pred_folds <- pred_best %>%
  group_split(Resample)

# æ‰‹åŠ¨è®¡ç®—æ¯ä¸ªfoldçš„ROCå’ŒPRCæ›²çº¿

# å­˜å‚¨æ‰€æœ‰foldçš„æ›²çº¿æ•°æ®
all_roc_data <- list()
all_prc_data <- list()
auc_values <- numeric(5)
prauc_values <- numeric(5)

for(i in 1:length(pred_folds)) {
  select_fold_data <- pred_folds[[i]]
  select_fold_data <- select_fold_data[patient_df[select_fold_data$rowIndex,]$Diagnosis == 2, ]
  # åˆ›å»º prediction å¯¹è±¡
  pred_obj <- prediction(select_fold_data$Yes, select_fold_data$obs == "Yes")
  
  # ROC æ›²çº¿
  roc_perf <- performance(pred_obj, "tpr", "fpr")
  auc_perf <- performance(pred_obj, "auc")
  auc_values[i] <- auc_perf@y.values[[1]]
  
  all_roc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    fpr = roc_perf@x.values[[1]],
    tpr = roc_perf@y.values[[1]],
    auc = auc_values[i]
  )
  
  # PRC æ›²çº¿
  prc_perf <- performance(pred_obj, "prec", "rec")
  
  # è®¡ç®— PRAUC
  prauc_perf <- performance(pred_obj, "aucpr")
  prauc_values[i] <- prauc_perf@y.values[[1]]
  
  # å¤„ç†precisionä¸­çš„NAå€¼ï¼ˆå½“recall=0æ—¶ï¼‰
  precision_vals <- prc_perf@y.values[[1]]
  recall_vals <- prc_perf@x.values[[1]]
  
  # ç§»é™¤NAå€¼
  valid_idx <- !is.na(precision_vals)
  
  all_prc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    recall = recall_vals[valid_idx],
    precision = precision_vals[valid_idx],
    prauc = prauc_values[i]
  )
}

# åˆå¹¶æ‰€æœ‰foldçš„æ•°æ®
roc_plot_data <- bind_rows(all_roc_data) %>%
  mutate(fold_label = paste0(fold, " (AUROC = ", round(auc, 3), ")"))

prc_plot_data <- bind_rows(all_prc_data) %>%
  mutate(fold_label = paste0(fold, " (AUPRC = ", round(prauc, 3), ")"))

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
mean_auroc <- mean(auc_values)
ci_auroc <- quantile(auc_values, c(0.025, 0.975))
mean_auprc <- mean(prauc_values)
ci_auprc <- quantile(prauc_values, c(0.025, 0.975))

# ç»˜åˆ¶ ROC æ›²çº¿
p_roc <- ggplot(roc_plot_data, aes(x = fpr, y = tpr, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_abline(linetype = "dashed", color = "grey50") +
  coord_equal() +
  labs(
    title = "Logistic Regression - 5-Fold Cross-Validation ROC Curves",
    subtitle = sprintf("Mean AUROC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auroc, ci_auroc[1], ci_auroc[2]),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    color = "Fold (AUROC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  )

print(p_roc)
ggsave("ROC_5-Fold_RF_sub.png", p_roc, width = 10, height = 7, dpi = 300)

#  ç»˜åˆ¶ PRC æ›²çº¿

# è®¡ç®—åŸºçº¿
total_positives <- sum(sapply(pred_folds, function(x) sum(x$obs == "Yes")))
total_samples <- sum(sapply(pred_folds, nrow))
baseline_precision <- total_positives / total_samples

p_prc <- ggplot(prc_plot_data, aes(x = recall, y = precision, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_hline(yintercept = baseline_precision, linetype = "dashed", color = "grey50") +
  annotate("text", x = 0.5, y = baseline_precision - 0.03, 
           label = paste("Random Classifier Baseline =", round(baseline_precision, 3)),
           color = "grey50", size = 3.5) +
  labs(
    title = "Logistic Regression - 5-Fold Cross-Validation PR Curves",
    subtitle = sprintf("Mean AUPRC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auprc, ci_auprc[1], ci_auprc[2]),
    x = "Recall (Sensitivity)",
    y = "Precision",
    color = "Fold (AUPRC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  ) +
  xlim(0, 1) + ylim(0, 1)

print(p_prc)
ggsave("PRC_5-Fold_RF_sub.png", p_prc, width = 10, height = 7, dpi = 300)
sub_ml_roc_data <- list(
  roc_data = all_roc_data,
  prc_data = all_prc_data,
  auc_values = auc_values,
  prauc_values = prauc_values,
  mean_auroc = mean_auroc,
  mean_auprc = mean_auprc,
  ci_auroc = ci_auroc,
  ci_auprc = ci_auprc
)
saveRDS(sub_ml_roc_data, file = "sub_ml_roc_data.rds")
# å¦‚æœè¿˜è¦è®¡ç®—åˆ†å±‚æŒ‡æ ‡

count_metric <- function(patient_df, fold_data, threshold, fold_id){
  pred_bin <- ifelse(fold_data$Yes >= threshold, "Yes", "No")
  control_flag <- patient_df[fold_data$rowIndex,]$Diagnosis
  TP_ <- sum(pred_bin == "Yes" & fold_data$obs == "Yes" & control_flag == 2)
  FP_ <- sum(pred_bin == "Yes" & fold_data$obs == "No" & control_flag == 2)
  FN_ <- sum(pred_bin == "No" & fold_data$obs == "Yes" & control_flag == 2)
  TN_ <- sum(pred_bin == "No" & fold_data$obs == "No" & control_flag == 2)
  sensitivity <- TP_ / (TP_ + FN_)
  specificity <- TN_ / (TN_ + FP_)
  precision <- TP_ / (TP_ + FP_)
  accuracy <- (TP_ + TN_) / sum(TP_+FP_+FN_+TN_)
  f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)
  youden_index <- sensitivity + specificity - 1
  return (
    tibble(
      fold = fold_id,
      sensitivity = sensitivity,
      specificity = specificity,
      precision = precision,
      accuracy = accuracy,
      f1_score = f1_score,
      best_threshold = threshold,
      youden_index = youden_index
    )
  )
}
}

if (SUB_THRESHOLD){
  fold_performance_sub = list()
  for(i in 1:length(pred_folds)) {
    select_fold_data <- pred_folds[[i]]
    select_fold_data <- select_fold_data[patient_df[select_fold_data$rowIndex,]$Diagnosis == 2, ]
    # è®¡ç®—è¯¥foldçš„Youden Index
    thresholds <- unique(sort(select_fold_data$Yes, decreasing = TRUE))
    
    youden_results <- map_dfr(thresholds, function(thresh) {
      pred_bin <- ifelse(select_fold_data$Yes >= thresh, "Yes", "No")
      # è®¡ç®—æ··æ·†çŸ©é˜µ
      cm <- table(Predicted = pred_bin, Actual = select_fold_data$obs)
      
      # ç¡®ä¿æ··æ·†çŸ©é˜µå®Œæ•´
      if(nrow(cm) == 1 || ncol(cm) == 1) {
        return(NULL)
      }
      
      TP <- cm["Yes", "Yes"]
      FP <- cm["Yes", "No"]
      FN <- cm["No", "Yes"]
      TN <- cm["No", "No"]
      
      # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
      sensitivity <- TP / (TP + FN)
      specificity <- TN / (TN + FP)
      precision <- TP / (TP + FP)
      accuracy <- (TP + TN) / sum(cm)
      f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)
      youden <- sensitivity + specificity - 1
      
      tibble(
        threshold = thresh,
        sensitivity = sensitivity,
        specificity = specificity,
        precision = precision,
        accuracy = accuracy,
        f1_score = f1_score,
        youden = youden
      )
    }) %>%
      filter(!is.na(youden))
    
    # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
    best_threshold <- youden_results %>%
      filter(youden == max(youden, na.rm = TRUE)) %>%
      dplyr::slice(1)
    
    fold_performance_sub[[i]] <- list(
      fold = i,
      best_threshold = best_threshold$threshold,
      sensitivity = best_threshold$sensitivity,
      specificity = best_threshold$specificity,
      precision = best_threshold$precision,
      accuracy = best_threshold$accuracy,
      f1_score = best_threshold$f1_score,
      youden_index = best_threshold$youden
    )
  }
  
  sub_result_df <- bind_rows(fold_performance_sub)
  avg_performance_sub <- sub_result_df %>%
    summarise(
      mean_sensitivity = mean(sensitivity),
      sd_sensitivity = sd(sensitivity),
      mean_specificity = mean(specificity),
      sd_specificity = sd(specificity),
      mean_precision = mean(precision),
      sd_precision = sd(precision),
      mean_accuracy = mean(accuracy),
      sd_accuracy = sd(accuracy),
      mean_f1_score = mean(f1_score),
      sd_f1_score = sd(f1_score),
      mean_youden_index = mean(youden_index),
      sd_youden_index = sd(youden_index)
    )
  sub_performance_long <- sub_result_df %>%
    select(-fold, -best_threshold) %>%
    pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
    mutate(metric = case_when(
      metric == "sensitivity" ~ "Sensitivity",
      metric == "specificity" ~ "Specificity",
      metric == "precision" ~ "Precision",
      metric == "accuracy" ~ "Accuracy",
      metric == "f1_score" ~ "F1-score",
      metric == "youden_index" ~ "Youden Index"
    ))
  
  p_fold_performance_sub <- ggplot(sub_performance_long, aes(x = metric, y = value)) +
    geom_boxplot(fill = "#3498db", alpha = 0.7) +
    geom_point(size = 3, alpha = 0.8) +
    labs(
      title = "5-Fold Cross-Validation Performance Metrics",
      subtitle = "Based on Youden Index Optimal Thresholds",
      x = "Metric",
      y = "Value"
    ) +
    theme_bw(base_size = 12) +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    ylim(0, 1)
  
  print(p_fold_performance_sub)
  ggsave("sub_threshold_peformance_ml.png", p_fold_performance_sub, width = 10, height = 7, dpi = 300)
  saveRDS(sub_performance_long,file="sub_performance_ml.rds")
}
### å…¨é‡æ•°æ®æ¨¡å‹çš„æ–°æ•°æ®éªŒè¯
if (NEWDATA){
  new_data <- read_xlsx("../data/select_data_model0806/new_data_mapped.xlsx")
  new_data[category_vars] <- lapply(new_data[category_vars], as.factor)
  new_data$psoriasis <- factor(new_data$psoriasis, 
                               levels = c("0", "1"), 
                               labels = c("No", "Yes"))
  
  new_pred <- predict(logit_model, new_data, type = "prob")
  if (BALANCE_SAMPLE){
    write.xlsx(new_pred$Yes, "../data/select_data_model0806/new_lr.xlsx", sheetName = "2",col.names=TRUE, row.names=FALSE, append=TRUE)
  }else{
    write.xlsx(new_pred$Yes, "../data/select_data_model0806/new_lr.xlsx", sheetName = "1",col.names=TRUE, row.names=FALSE, append=TRUE)
  }
  
}
