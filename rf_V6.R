##############################
## 0. å®‰è£…å¹¶åŠ è½½æ‰€éœ€åŒ…
##############################
needed_pkgs <- c("caret", "randomForest", "MLmetrics", "e1071", "ggplot2", 
                 "purrr", "dplyr", "tidyr", "readxl", "magrittr", "ROCR","xlsx")
new_pkgs <- needed_pkgs[!(needed_pkgs %in% installed.packages()[,"Package"])]
if(length(new_pkgs)) install.packages(new_pkgs)

# æ£€æŸ¥å¹¶å®‰è£…å¯é€‰åŒ…
if (!require("rmda")) {
  install.packages("rmda")
}

# åŠ è½½æ‰€æœ‰åŒ…
lapply(needed_pkgs, library, character.only = TRUE)
library(rmda)

set.seed(100)  # å¯å¤ç°çš„éšæœºç§å­
NEWDATA=F
BALANCE_SAMPLE=F
SUB_THRESHOLD=F
SUB_ROC=F
##############################
## 1. æ•°æ®é¢„å¤„ç†
##############################
# ç»¼åˆæ¨¡å‹
# patient_df <- read_excel("../data/202601/ccp_lasso.xlsx")
# å°æ¨¡å‹
patient_df <- read_excel('../data/202601/single_cohort_lasso.xlsx')
predictors <- setdiff(names(patient_df), "psoriasis")  # ç›®æ ‡å˜é‡æ˜¯ "psoriasis"
p <- length(predictors)

identify_categories <- function(x) {
  category_threshold <- 9
  if (is.numeric(x)) {
    return(length(unique(x)) <= category_threshold)
  }
  return(TRUE)
}
category_vars <- names(patient_df)[sapply(patient_df, identify_categories)]
category_vars <- setdiff(category_vars, "psoriasis")  # ç¡®ä¿psoriasisä¸è¢«å½“ä½œåˆ†ç±»å˜é‡
category_vars <- setdiff(category_vars, "Control")  # ç¡®ä¿psoriasisä¸è¢«å½“ä½œåˆ†ç±»å˜é‡
patient_df[category_vars] <- lapply(patient_df[category_vars], as.factor)
patient_df$psoriasis <- factor(patient_df$psoriasis, 
                               levels = c("0", "1"), 
                               labels = c("No", "Yes"))

##############################
## 2. è‡ªå®šä¹‰ F1-score è¯„ä¼°å‡½æ•°
##############################
f1_summary <- function(data, lev = NULL, model = NULL) {
  f1 <- F1_Score(y_true = data$obs,
                 y_pred = data$pred,
                 positive = "Yes")
  c(F1 = f1)
}

##############################
## 3. äº”æŠ˜äº¤å‰éªŒè¯å‚æ•°è®¾å®š
##############################
get_balanced_index <- function(x,name,value){
  # name = as.formula(name)
  idx_a0 <- which(x[name] == value)
  idx_a1 <- which(x[name] != value)
  folds_a0 <- createFolds(x$psoriasis[idx_a0], k = 5, returnTrain = FALSE)
  folds_a1 <- createFolds(x$psoriasis[idx_a1], k = 5, returnTrain = FALSE)
  index_list <- list()
  for (i in 1:5) {
    index_list[[i]] <- c(idx_a0[folds_a0[[i]]], idx_a1[folds_a1[[i]]])
  }
  return(index_list)
}
if (BALANCE_SAMPLE){
  test_ids <- get_balanced_index(patient_df,"Control",0)
  all_idx <- seq_len(nrow(patient_df))
  train_ids <- lapply(test_ids, function(val_idx) setdiff(all_idx, val_idx))
  patient_df <- select(patient_df, -"Control")
  ctrl <- trainControl(method = "cv",
                       number = 5,
                       summaryFunction = f1_summary,
                       index = train_ids,
                       indexOut = test_ids,
                       classProbs = TRUE,
                       savePredictions = "final",
                       verboseIter = FALSE)
} else {
  patient_df <- select(patient_df, -"Control")
  ctrl <- trainControl(method = "cv",
                       number = 5,
                       summaryFunction = f1_summary,
                       classProbs = TRUE,
                       savePredictions = "final",
                       verboseIter = FALSE)
}

##############################
## 4. è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹ (Random Forest)
##############################
rf_grid <- expand.grid(mtry = seq(2, min(13, p), by = 2))
n_trees <- 300  # å¢åŠ æ ‘çš„æ•°é‡ä»¥æé«˜ç¨³å®šæ€§

rf_model <- train(psoriasis ~ .,
                  data = patient_df,
                  method = "rf",
                  trControl = ctrl,
                  tuneGrid = rf_grid,
                  ntree = n_trees,
                  importance = TRUE,
                  metric = "F1")

##############################
## 5. æå–è¯„ä¼°ç»“æœå¹¶è¾“å‡º
##############################

# æå–äº¤å‰éªŒè¯ç»“æœ
cv_results <- rf_model$resample
mean_F1 <- mean(cv_results$F1)
best_F1 <- max(cv_results$F1)

cat("æ¨¡å‹è®­ç»ƒå®Œæˆ\n")
cat("æœ€ä½³å‚æ•°: mtry =", rf_model$bestTune$mtry, "\n")
cat("æ ‘çš„æ•°é‡: ntree =", n_trees, "\n")
cat("äº”æŠ˜å¹³å‡ F1-score:", round(mean_F1, 3), "\n")
cat("æœ€ä½³æŠ˜ F1-score:", round(best_F1, 3), "\n")

# æå–æœ€ä½³å‚æ•°ä¸‹çš„é¢„æµ‹ç»“æœ
best_params <- rf_model$bestTune
pred_best <- rf_model$pred %>%
  filter(mtry == best_params$mtry)

# æ ¡å‡†æ›²çº¿
calib_data_rf <- pred_best %>%
  select(prob = Yes, truth = obs) %>%
  mutate(model = "Random Forest")

# ä¿å­˜æ–‡ä»¶ - RDS ä¾›å¤šä¸ªæ¨¡å‹æ±‡æ€»ä½¿ç”¨
saveRDS(calib_data_rf, file = "calibration_data_rf.rds")
##############################
## 6. ROCå’ŒPRCæ›²çº¿ç»˜åˆ¶
##############################

# 6.1. å‡†å¤‡æ•°æ®
pred_folds <- pred_best %>%
  group_split(Resample)

# 6.2. æ‰‹åŠ¨è®¡ç®—æ¯ä¸ªfoldçš„ROCå’ŒPRCæ›²çº¿

# å­˜å‚¨æ‰€æœ‰foldçš„æ›²çº¿æ•°æ®
all_roc_data <- list()
all_prc_data <- list()
auc_values <- numeric(5)
prauc_values <- numeric(5)

for(i in 1:length(pred_folds)) {
  fold_data <- pred_folds[[i]]
  
  # åˆ›å»º prediction å¯¹è±¡
  pred_obj <- prediction(fold_data$Yes, fold_data$obs == "Yes")
  
  # ROC æ›²çº¿
  roc_perf <- performance(pred_obj, "tpr", "fpr")
  auc_perf <- performance(pred_obj, "auc")
  auc_values[i] <- auc_perf@y.values[[1]]
  
  all_roc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    fpr = roc_perf@x.values[[1]],
    tpr = roc_perf@y.values[[1]],
    auc = auc_values[i]
  )
  
  # PRC æ›²çº¿
  prc_perf <- performance(pred_obj, "prec", "rec")
  
  # è®¡ç®— PRAUC
  prauc_perf <- performance(pred_obj, "aucpr")
  prauc_values[i] <- prauc_perf@y.values[[1]]
  
  # å¤„ç†precisionä¸­çš„NAå€¼ï¼ˆå½“recall=0æ—¶ï¼‰
  precision_vals <- prc_perf@y.values[[1]]
  recall_vals <- prc_perf@x.values[[1]]
  
  # ç§»é™¤NAå€¼
  valid_idx <- !is.na(precision_vals)
  
  all_prc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    recall = recall_vals[valid_idx],
    precision = precision_vals[valid_idx],
    prauc = prauc_values[i]
  )
}

# åˆå¹¶æ‰€æœ‰foldçš„æ•°æ®
roc_plot_data <- bind_rows(all_roc_data) %>%
  mutate(fold_label = paste0(fold, " (AUROC = ", round(auc, 3), ")"))

prc_plot_data <- bind_rows(all_prc_data) %>%
  mutate(fold_label = paste0(fold, " (AUPRC = ", round(prauc, 3), ")"))

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
mean_auroc <- mean(auc_values)
ci_auroc <- quantile(auc_values, c(0.025, 0.975))
mean_auprc <- mean(prauc_values)
ci_auprc <- quantile(prauc_values, c(0.025, 0.975))

# 6.3. ç»˜åˆ¶ ROC æ›²çº¿
p_roc <- ggplot(roc_plot_data, aes(x = fpr, y = tpr, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_abline(linetype = "dashed", color = "grey50") +
  coord_equal() +
  labs(
    title = "Random Forest - 5-Fold Cross-Validation ROC Curves",
    subtitle = sprintf("Mean AUROC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auroc, ci_auroc[1], ci_auroc[2]),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    color = "Fold (AUROC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  )

print(p_roc)
ggsave("ROC_5-Fold_RF.png", p_roc, width = 10, height = 7, dpi = 300)

# 6.4. ç»˜åˆ¶ PRC æ›²çº¿

# è®¡ç®—åŸºçº¿
total_positives <- sum(sapply(pred_folds, function(x) sum(x$obs == "Yes")))
total_samples <- sum(sapply(pred_folds, nrow))
baseline_precision <- total_positives / total_samples

p_prc <- ggplot(prc_plot_data, aes(x = recall, y = precision, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_hline(yintercept = baseline_precision, linetype = "dashed", color = "grey50") +
  annotate("text", x = 0.5, y = baseline_precision - 0.03, 
           label = paste("Random Classifier Baseline =", round(baseline_precision, 3)),
           color = "grey50", size = 3.5) +
  labs(
    title = "Random Forest - 5-Fold Cross-Validation PR Curves",
    subtitle = sprintf("Mean AUPRC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auprc, ci_auprc[1], ci_auprc[2]),
    x = "Recall (Sensitivity)",
    y = "Precision",
    color = "Fold (AUPRC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  ) +
  xlim(0, 1) + ylim(0, 1)

print(p_prc)
ggsave("PRC_5-Fold_RF.png", p_prc, width = 10, height = 7, dpi = 300)

# 6.5. æ·»åŠ å¹³å‡æ›²çº¿çš„ROCå›¾

# è®¡ç®—å¹³å‡ ROC æ›²çº¿
fpr_seq <- seq(0, 1, length.out = 100)
tpr_interp <- matrix(NA, nrow = length(fpr_seq), ncol = 5)

for(i in 1:5) {
  fold_roc <- all_roc_data[[i]]
  f <- approxfun(fold_roc$fpr, fold_roc$tpr, rule = 2)
  tpr_interp[, i] <- f(fpr_seq)
}

avg_roc <- data.frame(
  fpr = fpr_seq,
  tpr = rowMeans(tpr_interp),
  tpr_lower = apply(tpr_interp, 1, quantile, 0.025),
  tpr_upper = apply(tpr_interp, 1, quantile, 0.975)
)

# å¸¦å¹³å‡æ›²çº¿çš„ ROC å›¾
p_roc_with_avg <- p_roc +
  geom_ribbon(data = avg_roc, 
              aes(x = fpr, ymin = tpr_lower, ymax = tpr_upper),
              fill = "black", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = avg_roc, 
            aes(x = fpr, y = tpr),
            color = "black", size = 1.5, inherit.aes = FALSE)

print(p_roc_with_avg)
ggsave("ROC_5-Fold_RF_with_average.png", p_roc_with_avg, width = 8, height = 7, dpi = 300)

##############################
## 7. åŸºäºYouden Indexçš„éªŒè¯åˆ†æ
##############################

# 7.1 å¯¹æ¯ä¸ªfoldè®¡ç®—æœ€ä½³é˜ˆå€¼å’Œæ€§èƒ½æŒ‡æ ‡
fold_performance <- list()

for(i in 1:length(pred_folds)) {
  fold_data <- pred_folds[[i]]
  # è®¡ç®—è¯¥foldçš„Youden Index
  thresholds <- unique(sort(fold_data$Yes, decreasing = TRUE))
  
  youden_results <- map_dfr(thresholds, function(thresh) {
    pred_bin <- ifelse(fold_data$Yes >= thresh, "Yes", "No")
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm <- table(Predicted = pred_bin, Actual = fold_data$obs)
    
    # ç¡®ä¿æ··æ·†çŸ©é˜µå®Œæ•´
    if(nrow(cm) == 1 || ncol(cm) == 1) {
      return(NULL)
    }
    
    TP <- cm["Yes", "Yes"]
    FP <- cm["Yes", "No"]
    FN <- cm["No", "Yes"]
    TN <- cm["No", "No"]
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    sensitivity <- TP / (TP + FN)
    specificity <- TN / (TN + FP)
    precision <- TP / (TP + FP)
    accuracy <- (TP + TN) / sum(cm)
    f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)
    youden <- sensitivity + specificity - 1
    
    tibble(
      threshold = thresh,
      sensitivity = sensitivity,
      specificity = specificity,
      precision = precision,
      accuracy = accuracy,
      f1_score = f1_score,
      youden = youden
    )
  }) %>%
    filter(!is.na(youden))
  
  # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
  best_threshold <- youden_results %>%
    filter(youden == max(youden, na.rm = TRUE)) %>%
    dplyr::slice(1)
  
  fold_performance[[i]] <- list(
    fold = i,
    best_threshold = best_threshold$threshold,
    sensitivity = best_threshold$sensitivity,
    specificity = best_threshold$specificity,
    precision = best_threshold$precision,
    accuracy = best_threshold$accuracy,
    f1_score = best_threshold$f1_score,
    youden_index = best_threshold$youden
  )
}

# 7.2 æ±‡æ€»5æŠ˜çš„å¹³å‡æ€§èƒ½

performance_df <- bind_rows(fold_performance)

# è®¡ç®—å¹³å‡æ€§èƒ½å’Œæ ‡å‡†å·®
avg_performance <- performance_df %>%
  summarise(
    mean_threshold = mean(best_threshold),
    sd_threshold = sd(best_threshold),
    mean_sensitivity = mean(sensitivity),
    sd_sensitivity = sd(sensitivity),
    mean_specificity = mean(specificity),
    sd_specificity = sd(specificity),
    mean_precision = mean(precision),
    sd_precision = sd(precision),
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy),
    mean_f1_score = mean(f1_score),
    sd_f1_score = sd(f1_score),
    mean_youden_index = mean(youden_index),
    sd_youden_index = sd(youden_index)
  )

# 7.3 è¾“å‡ºéªŒè¯ç»“æœ
cat("\n", rep("=", 60), "\n", sep = "")
cat("åŸºäºYouden Indexçš„5æŠ˜äº¤å‰éªŒè¯æ€§èƒ½è¯„ä¼°\n")
cat(rep("=", 60), "\n", sep = "")

cat("\nã€å„æŠ˜è¯¦ç»†ç»“æœã€‘\n")
for(i in 1:5) {
  cat(sprintf("\nFold %d:\n", i))
  cat(sprintf("  æœ€ä½³é˜ˆå€¼: %.3f\n", fold_performance[[i]]$best_threshold))
  cat(sprintf("  çµæ•åº¦: %.3f\n", fold_performance[[i]]$sensitivity))
  cat(sprintf("  ç‰¹å¼‚æ€§: %.3f\n", fold_performance[[i]]$specificity))
  cat(sprintf("  ç²¾ç¡®åº¦: %.3f\n", fold_performance[[i]]$precision))
  cat(sprintf("  å‡†ç¡®ç‡: %.3f\n", fold_performance[[i]]$accuracy))
  cat(sprintf("  F1-score: %.3f\n", fold_performance[[i]]$f1_score))
  cat(sprintf("  Youden Index: %.3f\n", fold_performance[[i]]$youden_index))
}

cat("\nã€5æŠ˜å¹³å‡æ€§èƒ½ (å‡å€¼ Â± æ ‡å‡†å·®)ã€‘\n")
cat(sprintf("æœ€ä½³é˜ˆå€¼: %.3f Â± %.3f\n", avg_performance$mean_threshold, avg_performance$sd_threshold))
cat(sprintf("çµæ•åº¦ (Sensitivity): %.3f Â± %.3f\n", avg_performance$mean_sensitivity, avg_performance$sd_sensitivity))
cat(sprintf("ç‰¹å¼‚æ€§ (Specificity): %.3f Â± %.3f\n", avg_performance$mean_specificity, avg_performance$sd_specificity))
cat(sprintf("ç²¾ç¡®åº¦ (Precision): %.3f Â± %.3f\n", avg_performance$mean_precision, avg_performance$sd_precision))
cat(sprintf("å‡†ç¡®ç‡ (Accuracy): %.3f Â± %.3f\n", avg_performance$mean_accuracy, avg_performance$sd_accuracy))
cat(sprintf("F1-score: %.3f Â± %.3f\n", avg_performance$mean_f1_score, avg_performance$sd_f1_score))
cat(sprintf("Youden Index: %.3f Â± %.3f\n", avg_performance$mean_youden_index, avg_performance$sd_youden_index))

# 7.4 å¯è§†åŒ–å„æŠ˜æ€§èƒ½
performance_long <- performance_df %>%
  select(-fold, -best_threshold) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  mutate(metric = case_when(
    metric == "sensitivity" ~ "Sensitivity",
    metric == "specificity" ~ "Specificity",
    metric == "precision" ~ "Precision",
    metric == "accuracy" ~ "Accuracy",
    metric == "f1_score" ~ "F1-score",
    metric == "youden_index" ~ "Youden Index"
  ))

p_fold_performance <- ggplot(performance_long, aes(x = metric, y = value)) +
  geom_boxplot(fill = "#3498db", alpha = 0.7) +
  geom_point(size = 3, alpha = 0.8) +
  labs(
    title = "5-Fold Cross-Validation Performance Metrics",
    subtitle = "Based on Youden Index Optimal Thresholds",
    x = "Metric",
    y = "Value"
  ) +
  theme_bw(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  ylim(0, 1)

print(p_fold_performance)
ggsave("fold_performance_metrics_rf.png", p_fold_performance, width = 8, height = 6, dpi = 300)
saveRDS(performance_long,file="performance_rf.rds")
##############################
## 8. å˜é‡é‡è¦æ€§åˆ†æ
##############################

merge_factor_importance <- function(importance_df, original_data, target_var = "psoriasis") {
  # è·å–åŸå§‹æ•°æ®ä¸­çš„å˜é‡åï¼ˆä¸åŒ…æ‹¬ç›®æ ‡å˜é‡ï¼‰
  original_vars <- setdiff(names(original_data), target_var)
  
  # è·å–åˆ†ç±»å˜é‡åˆ—è¡¨
  factor_vars <- names(original_data)[sapply(original_data, is.factor)]
  factor_vars <- setdiff(factor_vars, target_var)
  
  # åˆ›å»ºæ˜ å°„å‡½æ•°
  map_to_original <- function(var_name) {
    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯åŸå§‹å˜é‡å
    if (var_name %in% original_vars) {
      return(var_name)
    }
    
    # å¯¹äºåˆ†ç±»å˜é‡ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å…¶å­åˆ†å±‚
    for (fvar in factor_vars) {
      # æ£€æŸ¥å¤šç§å¯èƒ½çš„å‘½åæ¨¡å¼
      patterns <- c(
        paste0("^", fvar, "\\."),     # factor.level
        paste0("^", fvar, "[0-9]+$"), # factor1, factor2
        paste0("^", fvar, "[A-Za-z]+$") # factorA, factorB
      )
      
      if (any(sapply(patterns, function(p) grepl(p, var_name)))) {
        return(fvar)
      }
    }
    
    # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›åŸå§‹åç§°
    return(var_name)
  }
  
  # åº”ç”¨æ˜ å°„
  importance_df$MainVariable <- sapply(importance_df$Variable, map_to_original)
  
  # æ±‡æ€»é‡è¦æ€§
  importance_summary <- importance_df %>%
    group_by(MainVariable) %>%
    summarise(
      Importance = mean(Importance),  # ä½¿ç”¨sumåˆå¹¶
      n_sublevels = n()              # è®°å½•å­åˆ†å±‚æ•°é‡
    ) %>%
    rename(Variable = MainVariable) %>%
    arrange(desc(Importance))
  
  return(importance_summary)
}
# æå–å˜é‡é‡è¦æ€§
rf_imp <- importance(rf_model$finalModel, type = 1)
rf_imp_df <- data.frame(
  Variable = rownames(rf_imp),
  Importance = rf_imp[, "MeanDecreaseAccuracy"]
)

# åˆå¹¶å­åˆ†å±‚
rf_imp_summary <- merge_factor_importance(rf_imp_df, patient_df)

# æ‰“å°ç»“æœ
print("éšæœºæ£®æ—ç‰¹å¾é‡è¦æ€§æ’åï¼ˆåˆå¹¶åï¼‰ï¼š")
print(rf_imp_summary)

# ç»˜åˆ¶éšæœºæ£®æ—é‡è¦æ€§å›¾
topN <- min(10, nrow(rf_imp_summary))
p_rf <- ggplot(rf_imp_summary[1:topN, ], 
               aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_col(fill = "#2ca02c", alpha = 0.8) +
  coord_flip() +
  labs(
    title = sprintf("Random Forest Variable Importance (Top %d)", topN),
    x = NULL,
    y = "Mean Decrease in Accuracy"
  ) +
  theme_bw(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5),
    axis.text.y = element_text(size = 10)
  )

print(p_rf)
ggsave("rf_variable_importance.png", p_rf, width = 8, height = 6, dpi = 300)
saveRDS(rf_imp_summary, "rf_var_important.rds")
##############################
## 9. ä¿å­˜æ¨¡å‹ä¸ç»“æœ
##############################

# ä¿å­˜æ¨¡å‹
saveRDS(rf_model, file = "rf_best_model.rds")

# ä¿å­˜ROCæ•°æ®
rf_roc_data <- list(
  roc_data = all_roc_data,
  prc_data = all_prc_data,
  auc_values = auc_values,
  prauc_values = prauc_values,
  mean_auroc = mean_auroc,
  mean_auprc = mean_auprc,
  ci_auroc = ci_auroc,
  ci_auprc = ci_auprc
)
saveRDS(rf_roc_data, file = "rf_roc_data.rds")


# ä¿å­˜éªŒè¯æ€§èƒ½æ•°æ®
validation_results <- list(
  fold_performance = fold_performance,
  performance_df = performance_df,
  avg_performance = avg_performance
)
saveRDS(validation_results, file = "rf_validation_results.rds")

cat("\nğŸŸ¢ æ¨¡å‹å·²ä¿å­˜ä¸º rf_best_model.rds\n")
cat("ğŸŸ¢ ROC/PRCæ•°æ®å·²ä¿å­˜ä¸º rf_roc_data.rds\n")
cat("ğŸŸ¢ å˜é‡é‡è¦æ€§å·²ä¿å­˜ä¸º rf_variable_importance.rds\n")
cat("ğŸŸ¢ éªŒè¯ç»“æœå·²ä¿å­˜ä¸º rf_validation_results.rds\n")

##############################
## 10. å†³ç­–æ›²çº¿åˆ†æï¼ˆå¯é€‰ï¼‰
##############################

# å‡†å¤‡å†³ç­–æ›²çº¿åˆ†ææ‰€éœ€çš„æ•°æ®
dca_rf_df <- pred_best %>%
  select(prob = Yes, truth = obs) %>%
  mutate(
    model = "Random Forest",
    truth = ifelse(truth == "Yes", 1, 0)  # è½¬æ¢ä¸º0/1æ ¼å¼
  )

saveRDS(dca_rf_df, "dca_rf_df.rds")
cat("ğŸŸ¢ å†³ç­–æ›²çº¿æ•°æ®å·²ä¿å­˜ä¸º dca_rf_df.rds\n")

##############################
## 11. æ¨¡å‹æ€§èƒ½æ€»ç»“æŠ¥å‘Š
##############################
cat("\n", rep("=", 60), "\n", sep = "")
cat("Random Forest æ¨¡å‹äº”æŠ˜äº¤å‰éªŒè¯æ€§èƒ½æ€»ç»“\n")
cat(rep("=", 60), "\n", sep = "")

cat("\n1. æ¨¡å‹å‚æ•°:\n")
cat("   - æ–¹æ³•: Random Forest\n")
cat("   - æœ€ä¼˜å‚æ•°: mtry =", rf_model$bestTune$mtry, "\n")
cat("   - æ ‘çš„æ•°é‡: ntree =", n_trees, "\n")

cat("\n2. ROC/PRCæ€§èƒ½:\n")
cat("   - å¹³å‡ AUROC:", round(mean_auroc, 3), 
    sprintf("(95%% CI: %.3f-%.3f)\n", ci_auroc[1], ci_auroc[2]))
cat("   - å¹³å‡ AUPRC:", round(mean_auprc, 3), 
    sprintf("(95%% CI: %.3f-%.3f)\n", ci_auprc[1], ci_auprc[2]))

cat("\n3. åŸºäºYouden Indexçš„éªŒè¯æ€§èƒ½ (å‡å€¼ Â± æ ‡å‡†å·®):\n")
cat("   - æœ€ä½³é˜ˆå€¼:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_threshold, avg_performance$sd_threshold))
cat("   - Sensitivity:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_sensitivity, avg_performance$sd_sensitivity))
cat("   - Specificity:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_specificity, avg_performance$sd_specificity))
cat("   - Precision:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_precision, avg_performance$sd_precision))
cat("   - Accuracy:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_accuracy, avg_performance$sd_accuracy))
cat("   - F1-score:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_f1_score, avg_performance$sd_f1_score))
cat("   - Youden Index:", sprintf("%.3f Â± %.3f\n", avg_performance$mean_youden_index, avg_performance$sd_youden_index))

cat("\n5. è¾“å‡ºæ–‡ä»¶:\n")
cat("   - æ¨¡å‹æ–‡ä»¶: rf_best_model.rds\n")
cat("   - ROC/PRCæ•°æ®: rf_roc_data.rds\n")
cat("   - éªŒè¯ç»“æœ: rf_validation_results.rds\n")
cat("   - å†³ç­–æ›²çº¿æ•°æ®: dca_rf_df.rds\n")
cat("   - å˜é‡é‡è¦æ€§: rf_variable_importance.rds\n")
cat("   - å›¾å½¢æ–‡ä»¶:\n")
cat("     * ROC_5-Fold_RF.png\n")
cat("     * PRC_5-Fold_RF.png\n")
cat("     * ROC_5-Fold_RF_with_average.png\n")
cat("     * fold_performance_metrics.png\n")
cat("     * variable_importance_rf.png\n")

cat("\n", rep("=", 60), "\n", sep = "")
# å®Œæˆæç¤º
cat("\nâœ… Random Forestæ¨¡å‹åˆ†æå®Œæˆï¼\n")


##### å¦‚æœè¿˜è¦è®¡ç®—åˆ†å±‚æŒ‡æ ‡,å¹¶ä»¥åˆ†å±‚ç‰¹å¾ä½œä¸ºåŸºå‡†è°ƒæ•´é˜ˆå€¼   ###### 
##### å¦‚æœéœ€è¦å…·å¤‡ç‰¹å®šåˆ†å±‚ç‰¹å¾æ‚£è€…çš„ROCå’ŒPRC              ######
if (SUB_ROC){
  # å‡†å¤‡æ•°æ®
pred_folds <- pred_best %>%
  group_split(Resample)

# æ‰‹åŠ¨è®¡ç®—æ¯ä¸ªfoldçš„ROCå’ŒPRCæ›²çº¿

# å­˜å‚¨æ‰€æœ‰foldçš„æ›²çº¿æ•°æ®
all_roc_data <- list()
all_prc_data <- list()
auc_values <- numeric(5)
prauc_values <- numeric(5)

for(i in 1:length(pred_folds)) {
  select_fold_data <- pred_folds[[i]]
  select_fold_data <- select_fold_data[patient_df[select_fold_data$rowIndex,]$Diagnosis == 2, ]
  # åˆ›å»º prediction å¯¹è±¡
  pred_obj <- prediction(select_fold_data$Yes, select_fold_data$obs == "Yes")
  
  # ROC æ›²çº¿
  roc_perf <- performance(pred_obj, "tpr", "fpr")
  auc_perf <- performance(pred_obj, "auc")
  auc_values[i] <- auc_perf@y.values[[1]]
  
  all_roc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    fpr = roc_perf@x.values[[1]],
    tpr = roc_perf@y.values[[1]],
    auc = auc_values[i]
  )
  
  # PRC æ›²çº¿
  prc_perf <- performance(pred_obj, "prec", "rec")
  
  # è®¡ç®— PRAUC
  prauc_perf <- performance(pred_obj, "aucpr")
  prauc_values[i] <- prauc_perf@y.values[[1]]
  
  # å¤„ç†precisionä¸­çš„NAå€¼ï¼ˆå½“recall=0æ—¶ï¼‰
  precision_vals <- prc_perf@y.values[[1]]
  recall_vals <- prc_perf@x.values[[1]]
  
  # ç§»é™¤NAå€¼
  valid_idx <- !is.na(precision_vals)
  
  all_prc_data[[i]] <- data.frame(
    fold = paste0("Fold ", i),
    recall = recall_vals[valid_idx],
    precision = precision_vals[valid_idx],
    prauc = prauc_values[i]
  )
}

# åˆå¹¶æ‰€æœ‰foldçš„æ•°æ®
roc_plot_data <- bind_rows(all_roc_data) %>%
  mutate(fold_label = paste0(fold, " (AUROC = ", round(auc, 3), ")"))

prc_plot_data <- bind_rows(all_prc_data) %>%
  mutate(fold_label = paste0(fold, " (AUPRC = ", round(prauc, 3), ")"))

# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
mean_auroc <- mean(auc_values)
ci_auroc <- quantile(auc_values, c(0.025, 0.975))
mean_auprc <- mean(prauc_values)
ci_auprc <- quantile(prauc_values, c(0.025, 0.975))

# ç»˜åˆ¶ ROC æ›²çº¿
p_roc <- ggplot(roc_plot_data, aes(x = fpr, y = tpr, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_abline(linetype = "dashed", color = "grey50") +
  coord_equal() +
  labs(
    title = "Random Forest - 5-Fold Cross-Validation ROC Curves",
    subtitle = sprintf("Mean AUROC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auroc, ci_auroc[1], ci_auroc[2]),
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)",
    color = "Fold (AUROC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  )

print(p_roc)
ggsave("ROC_5-Fold_RF_sub.png", p_roc, width = 10, height = 7, dpi = 300)

#  ç»˜åˆ¶ PRC æ›²çº¿

# è®¡ç®—åŸºçº¿
total_positives <- sum(sapply(pred_folds, function(x) sum(x$obs == "Yes")))
total_samples <- sum(sapply(pred_folds, nrow))
baseline_precision <- total_positives / total_samples

p_prc <- ggplot(prc_plot_data, aes(x = recall, y = precision, color = fold_label)) +
  geom_line(size = 1, alpha = 0.8) +
  geom_hline(yintercept = baseline_precision, linetype = "dashed", color = "grey50") +
  annotate("text", x = 0.5, y = baseline_precision - 0.03, 
           label = paste("Random Classifier Baseline =", round(baseline_precision, 3)),
           color = "grey50", size = 3.5) +
  labs(
    title = "Random Forest - 5-Fold Cross-Validation PR Curves",
    subtitle = sprintf("Mean AUPRC = %.3f (95%% CI: %.3f - %.3f)", 
                       mean_auprc, ci_auprc[1], ci_auprc[2]),
    x = "Recall (Sensitivity)",
    y = "Precision",
    color = "Fold (AUPRC)"
  ) +
  scale_color_viridis_d() +
  theme_bw(base_size = 14) +
  theme(
    legend.position = "right",
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 11),
    legend.key.height = unit(1.2, "lines"),
    legend.box.background = element_rect(color = "black", size = 0.5),
    legend.margin = ggplot2::margin(10, 10, 10, 10),
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    plot.margin = ggplot2::margin(10, 10, 10, 10)
  ) +
  xlim(0, 1) + ylim(0, 1)

print(p_prc)
ggsave("PRC_5-Fold_RF_sub.png", p_prc, width = 10, height = 7, dpi = 300)
sub_rf_roc_data <- list(
  roc_data = all_roc_data,
  prc_data = all_prc_data,
  auc_values = auc_values,
  prauc_values = prauc_values,
  mean_auroc = mean_auroc,
  mean_auprc = mean_auprc,
  ci_auroc = ci_auroc,
  ci_auprc = ci_auprc
)
saveRDS(sub_rf_roc_data, file = "sub_rf_roc_data_sub.rds")

# æå–æ ¡å‡†æ›²çº¿
pred_best_subgroup <- pred_best %>%
  filter(patient_df[rowIndex, ]$Diagnosis == 2)
calib_data_sub_rf <- pred_best_subgroup %>%
  select(prob = Yes, truth = obs) %>%
  mutate(
    model = "Random Forest",
    subgroup = "Diagnosis == 2"
  )

saveRDS(calib_data_sub_rf, "calibration_data_rf_subgroup.rds")
}

# é¦–å…ˆè®¡ç®—åˆ†å±‚ç‰¹å¾å¯¼å‘çš„é˜ˆå€¼
if (SUB_THRESHOLD){
  fold_performance_sub = list()
for(i in 1:length(pred_folds)) {
  select_fold_data <- pred_folds[[i]]
  select_fold_data <- select_fold_data[patient_df[select_fold_data$rowIndex,]$Diagnosis == 2, ]
  # è®¡ç®—è¯¥foldçš„Youden Index
  thresholds <- unique(sort(select_fold_data$Yes, decreasing = TRUE))
  
  youden_results <- map_dfr(thresholds, function(thresh) {
    pred_bin <- ifelse(select_fold_data$Yes >= thresh, "Yes", "No")
    # è®¡ç®—æ··æ·†çŸ©é˜µ
    cm <- table(Predicted = pred_bin, Actual = select_fold_data$obs)
    
    # ç¡®ä¿æ··æ·†çŸ©é˜µå®Œæ•´
    if(nrow(cm) == 1 || ncol(cm) == 1) {
      return(NULL)
    }
    
    TP <- cm["Yes", "Yes"]
    FP <- cm["Yes", "No"]
    FN <- cm["No", "Yes"]
    TN <- cm["No", "No"]
    
    # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    sensitivity <- TP / (TP + FN)
    specificity <- TN / (TN + FP)
    precision <- TP / (TP + FP)
    accuracy <- (TP + TN) / sum(cm)
    f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)
    youden <- sensitivity + specificity - 1
    
    tibble(
      threshold = thresh,
      sensitivity = sensitivity,
      specificity = specificity,
      precision = precision,
      accuracy = accuracy,
      f1_score = f1_score,
      youden = youden
    )
  }) %>%
    filter(!is.na(youden))
  
  # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
  best_threshold <- youden_results %>%
    filter(youden == max(youden, na.rm = TRUE)) %>%
    dplyr::slice(1)
  
  fold_performance_sub[[i]] <- list(
    fold = i,
    best_threshold = best_threshold$threshold,
    sensitivity = best_threshold$sensitivity,
    specificity = best_threshold$specificity,
    precision = best_threshold$precision,
    accuracy = best_threshold$accuracy,
    f1_score = best_threshold$f1_score,
    youden_index = best_threshold$youden
  )
}

sub_result_df <- bind_rows(fold_performance_sub)
avg_performance_sub <- sub_result_df %>%
  summarise(
    mean_sensitivity = mean(sensitivity),
    sd_sensitivity = sd(sensitivity),
    mean_specificity = mean(specificity),
    sd_specificity = sd(specificity),
    mean_precision = mean(precision),
    sd_precision = sd(precision),
    mean_accuracy = mean(accuracy),
    sd_accuracy = sd(accuracy),
    mean_f1_score = mean(f1_score),
    sd_f1_score = sd(f1_score),
    mean_youden_index = mean(youden_index),
    sd_youden_index = sd(youden_index)
  )
sub_performance_long <- sub_result_df %>%
  select(-fold, -best_threshold) %>%
  pivot_longer(everything(), names_to = "metric", values_to = "value") %>%
  mutate(metric = case_when(
    metric == "sensitivity" ~ "Sensitivity",
    metric == "specificity" ~ "Specificity",
    metric == "precision" ~ "Precision",
    metric == "accuracy" ~ "Accuracy",
    metric == "f1_score" ~ "F1-score",
    metric == "youden_index" ~ "Youden Index"
  ))

p_fold_performance_sub <- ggplot(sub_performance_long, aes(x = metric, y = value)) +
  geom_boxplot(fill = "#3498db", alpha = 0.7) +
  geom_point(size = 3, alpha = 0.8) +
  labs(
    title = "5-Fold Cross-Validation Performance Metrics",
    subtitle = "Based on Youden Index Optimal Thresholds",
    x = "Metric",
    y = "Value"
  ) +
  theme_bw(base_size = 12) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  ) +
  ylim(0, 1)

print(p_fold_performance_sub)
ggsave("sub_threshold_peformance_rf.png", p_fold_performance_sub, width = 10, height = 7, dpi = 300)
saveRDS(sub_performance_long,file="sub_performance_rf.rds")
saveRDS(sub_result_df, file="sub_threshold_rf.rds")
}


### å…¨é‡æ•°æ®æ¨¡å‹çš„æ–°æ•°æ®éªŒè¯
if (NEWDATA){
  new_data <- read_xlsx("../data/select_data_model0806/new_data_mapped.xlsx")
  new_data[category_vars] <- lapply(new_data[category_vars], as.factor)
  new_data$psoriasis <- factor(new_data$psoriasis, 
                               levels = c("0", "1"), 
                               labels = c("No", "Yes"))
  
  new_pred <- predict(rf_model, new_data, type = "prob")
  if (BALANCE_SAMPLE){
    write.xlsx(new_pred$Yes, "../data/select_data_model0806/new_rf.xlsx", sheetName = "2",col.names=TRUE, row.names=FALSE, append=TRUE)
  }else{
    write.xlsx(new_pred$Yes, "../data/select_data_model0806/new_rf.xlsx", sheetName = "1",col.names=TRUE, row.names=FALSE, append=TRUE)
  }
  
}

